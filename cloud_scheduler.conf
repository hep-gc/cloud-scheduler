#
# A sample configuration file for the cloud scheduler.
#

[global]

# cloud_resource_config is the path to the default list of resources you want
#           to use with Cloud Scheduler. If no file is supplied on the command
#           line (-c some_cloud | --cloud-config=some_cloud), this file will
#           be used.
#
cloud_resource_config: /etc/cloudscheduler/cloud_resources.conf 

# condor_retrieval_method is the method by which Cloud Scheduler gets job and 
#           resource data. Cloud Scheduler uses this data to determine how 
#           many VMs to boot for a user's jobs. There are two options: local
#           and soap. The SOAP method uses the Condor SOAP API to retrieve 
#           the data from Condor, and uses the condor_webservice_url and 
#           condor_collector_url options for contacting Condor. The local 
#           method simply runs the equivalent of 'condor_q -l' or
#           'condor_status -l' at the command line. If you like, you can 
#           change the command that Cloud Scheduler runs, for example, if
#           your central manager is on a different machine, you can make the
#           command something like 'ssh condor.your.org condor_status -l'.
#           This depends on the condor_q_command and the condor_status_command
#           options.
#
#           At this time, the soap method is considerably slower than the local
#           method.
#
#           The default is local
#
#condor_retrieval_method: local

# condor_webservice_url must point to the URL of the SOAP service on your
#           Condor pool, and the port on which it is running (usually 8080).
#                       
#   The default value is http://localhost:8080
condor_webservice_url: http://localhost:8080

# condor_collector_url must point to the URL of the SOAP service for your
#           Condor collector, and the port on which it is running (usually 9618).
#                       
#   The default value is http://localhost:9618
condor_collector_url: http://localhost:9618

# condor_q_command this is the command that Cloud Scheduler runs to get Condor
#           job data. If you like, you can change the command that Cloud 
#           Scheduler runs, for example, if your central manager is on a
#           different machine, you can make the command something like 
#           'ssh condor.your.org condor_q -l'.
#
#    The default value is 'condor_q -l'
#condor_q_command: condor_q -l

# condor_status_command this is the command that Cloud Scheduler runs to get Condor
#           machine data. If you like, you can change the command that Cloud 
#           Scheduler runs, for example, if your central manager is on a
#           different machine, you can make the command something like 
#           'ssh condor.your.org condor_status -l'.
#
#    The default value is 'condor_status -l'
#condor_status_command: condor_status -l

# condor_status_master_command this is the command that Cloud Scheduler runs to get Condor
#           master daemon data. If you like, you can change the command that Cloud 
#           Scheduler runs, for example, if your central manager is on a
#           different machine, you can make the command something like 
#           'ssh condor.your.org condor_status -master -l'.
#
#    The default value is 'condor_status -master -l'
#condor_status_master_command: condor_status -master -l

# condor_hold_command this is the command that Cloud Scheduler runs to get Condor
            to hold jobs. If you like, you can change the command that Cloud 
#           Scheduler runs, for example, if your central manager is on a
#           different machine, you can make the command something like 
#           'ssh condor.your.org condor_hold'.
#
#    The default value is 'condor_hold'
#condor_hold_command: condor_hold

# condor_release_command this is the command that Cloud Scheduler runs to get Condor
            to release jobs. If you like, you can change the command that Cloud 
#           Scheduler runs, for example, if your central manager is on a
#           different machine, you can make the command something like 
#           'ssh condor.your.org condor_release'.
#
#    The default value is 'condor_release'
#condor_release_command: condor_release

# condor_off_command this is the command that Cloud Scheduler runs to manange VMs
#           in the condor pool. If the central manager is on a different machine
#           you'll need to set a cloudscheduler_ssh_key below.
#
#    The default value is '/usr/sbin/condor_off
#condor_off_command: /usr/sbin/condor_off

# condor_on_command this is the command that Cloud Scheduler runs to manange VMs
#           in the condor pool. If the central manager is on a different machine
#           you'll need to set a cloudscheduler_ssh_key below.
#
#    The default value is '/usr/sbin/condor_on
#condor_on_command: /usr/sbin/condor_on

# ssh_path - location of ssh
#
#   The default is /usr/bin/ssh
#ssh_path: /usr/bin/ssh

# openssl_path - location of openssl
#
#   The default is /usr/bin/openssl
#openssl_path: /usr/bin/openssl

# condor_host_on_vm is the hostname of the central manager that the Condor
#           daemons on the VM connect to. This is normally derived from the
#           condor_webservice_url option, but some setups (for example, those
#           that use OpenVPN) might need a diferent hostname for the VMs than
#           for Cloud Scheduler.
#
#   The default value is the hostname from condor_webservice_url. If this value
#   is localhost, it won't be sent to the VM.
#
#condor_host_on_vm: your.condor.server.edu

# condor_context_file is the location on your VM image where cloud_scheduler
#           should write the address of your Condor central manager machine
#           This is required to automatically contextualize your VM to point
#           to your Condor Pool
#                       
#   The default value is nothing, so no contextualization will happen unless
#   a value is specifically placed here
#condor_context_file: /etc/condor/central_manager

# vm_lifetime is the maximum time in minutes that you would like your VMs to
#           live.  Cloud Scheduler may shut them down before this point, but
#           this is the length of time that will be leased from cloud resources.
#
#   The default is 10080 minutes (1 week)
#vm_lifetime: 10080

# cert_file is the location of the (x509 or other) certificate that you would
#           like copied to your virtual machine. This is useful for setting
#           up VPN connections
#
#   There is no default.
#cert_file: /your/cert.pem

# key_file is the location of the (x509 or other) key that you would
#           like copied to your virtual machine. This is useful for setting
#           up VPN connections
#
#   There is no default.
#key_file: /your/key.pem

# cert_file_on_vm is where the (x509 or other) certificate cert_file
#           will be copied to on the booted VM.
#
#   The default is the location of cert_file
#cert_file_on_vm: /your/cert.pem

# key_file_on_vm is where the (x509 or other) key key_file
#           will be copied to on the booted VM.
#
#   The default is the location of key_file
#key_file_on_vm: /your/cert.pem

# ca_root_certs is the root file for the certificate authority being used
#           that will be contextualized into the VM.
#
#   The default value is None
#ca_root_certs: None

# ca_signing_policies is the signining policies for the certificate authority
#           that will be contextualized into the VM.
#
#   The default value is None
#ca_signing_policies: None


# cloudscheduler_ssh_key is the ssh key CloudScheduler will use to execute 
#           commands on the Condor central manager. This needs to be
#           a password-less key accessible by CloudScheduler.
#
#   There is no default.
#cloudscheduler_ssh_key: /your/.ssh/ssh_key

# image_attach_device is the device the image specified for a job is attached
#           to. 
#                       
#   The default value is sda
#image_attach_device: sda

# scratch_attach_device is the device the scratch space specified for a job is
#           attached to. 
#                       
#   The default value is sdb
#scratch_attach_device: sdb

# info_server_port is the port that the xmlrpc server that serves information
#           to tools like cloud_status uses. You may need to change this
#           to something other than the default if you have a conflict
#           with some other program, but you probably won't need to.
#
#   The default value is 8111
#info_server_port: 8111

# workspace_path is the path to the workspace (or workspace.sh) executable
#           used by Cloud Scheduler to start VMs on Nimbus resources.
#
#   The default value is "workspace", which assumes the executable is
#   in the path.
#workspace_path: /path/to/workspace
#
# persistence_file is the path to the Cloud Scheduler persistence file
#           which maintains Cloud Scheduler state information in case
#           of an unexpected exit from Cloud Scheduler (power outage, etc)
#
#   The default value is /var/lib/cloudscheduler.persistence
#persistence_file: /var/lib/cloudscheduler.persistence

# polling_error_threshold is the number of times a VM returns a error
#           during status polling before being shutdown
#   The default value is 10
# polling_error_threshold: 10

# condor_register_time_limit is the number of minutes Cloud Scheduler waits
# for a VM to register with Condor before determining there has been an error
# during boot and will shutdown the VM.
#   The default value is 15 (minutes)
#condor_register_time_limit: 15

# scheduling_algorithm specifies how Cloud Scheduler will schedule jobs.
#           'fairshare' Attempts to give each user an equal amount of
#           cloud resources to use, and balance resources between users.
#           It includes several options regarding how machines are shutdown,
#           sharing metrics, and support for high priority jobs
#           
#           'fifo' Attempts to schedules jobs based on the order that they come in.
#
#   The default value is 'fairshare'
#scheduling_algoritm: fairshare

# job_distribution_type specifies how Cloud Scheduler will determine job shares.
#           for 'normal' distribution, a users' jobs will be evalutated based on 
#           priority and jobs of same priority are treated first in, first out.
#           for 'split' distribution, a users' jobs will be evaluated based on
#           priority and jobs of the same priority will get a split of their share
#
#   The default valus is 'normal'
#job_distribution_type: normal

# graceful_shutdown specifies if you want machines to only shutdown when no
#           job is running on them, this requires using condor_hold and 
#           condor_release on jobs and can affect performance, but will
#           prevent a job from being rescheduled due to Cloud_Scheduler
#           shutting down a job's VM once it has started running
#
#   The default is true
#graceful_shutdown: true

# gradeful_shutdown_method specifies the way CloudScheduler will shutdown
#           machines to minimize job interuptions.
#           'hold' will use condor_hold & condor_release to handle this - DEPRECATED
#           'off' will use condor_off to peacefully stop the condor startd
#           on the VM. This requires a password-less ssh to be setup from 
#           CloudScheduler to the Condor centeral manager. It is preferable
#           to use 'off' if possible.
#   The default is 'off'
#graceful_shutdown_method: off

# retire_before_lifetime specifies if you want Cloud Scheduler to attempt to
#           retire VMs before they reach their max vm_lifetime in order to 
#           minimize interrupted jobs caused by the VM being shutdown while a 
#           job is executing.
#           condor_off related configuration must be done to use this feature.
#
#   The default value is false
#retire_before_lifetime: false

# retire_before_lifetime_factor is amount of buffer CS will give a VM before 
#           retiring when near the max vm_lifetime. 
#           Cloud Scheduler tracks the run time of the last several jobs the VM
#           has run and will apply the factor to the average run time.
#           ie 1.5 will ensure there is average_time * 1.5 time remaining until 
#           vm_lifetime and if not will retire that VM so no more jobs
#           will run on it.
#
#   The default is 1.5 (Must be a float value greater than 1.0)
#retire_before_lifetime_factor: 1.5

# retire_missing_vms will make CloudScheduler attempt to retire VMs in condor 
#           that it once booted, but no longer has a record of. Retiring the VM
#           will allow CS to better manage the current jobs.
#
#   The default value is false
#retire_missing_vms: false

# clean_shutdown_idle will cause CloudScheduler to attempt to clean up VMs
#           that are sitting idle and unable to run jobs, this may be due to a 
#           problem in the condor Requirements expression for the job or in the
#           +VM* Attributes in the jdl. It will also attempt to hold related jobs.
#
#   The default value is False
#clean_shutdown_idle: False

# scheduling_metric selects the type of scheduling cloud_scheduler will
# use to balance resources between users.
#    The default value is slot, other option(s) are: memory, memory_cpu, memory_cpu_storage
#scheduling_metric: slot

# The distribution weights are used for the memory_cpu, and memory_cpu_storage 
#   scheduling metrics to adjust how Cloud Scheduler will balance resources.
#   Use a floating point value greater than 0.
#   The default is 1.0 for all weights.
#cpu_distribution_weight = 1.0
#memory_distribution_weight = 1.0
#storage_distribution_weight = 1.0

# getclouds specifies if you want to use cloud monitoring data from the
#   cloud-aggregator. More information about cloud-aggregator is here
#   https://wiki.gridx1.ca/twiki/bin/view/Main/CloudAggregatorOverview
#
#   The default value is false
#getclouds: False

# high_priority_job_support enables or disables use of high priority jobs
#   if support for high priority jobs is disabled any jobs marked as high
#   priority will be treated as normal jobs.
#
#   The default value is false
# high_priority_job_support: False

# high_priority_job_weight is the weighting used to determine any increased
#   share of resources that Cloud Scheduler will try to allocate to high priority
#   jobs. Use positive integer values.
#
#   The default value is 1 (no weight)
#high_priority_job_weight: 1

# scheduler_interval is the number of seconds between VM scheduling cycles.
#   Increasing this value will lower the load on the system, and decreasing
#   it will improve responsiveness. The default value is good for testing, 
#   but could result excessive load on a busy system.
#
#   The default value is 5
#scheduler_interval: 5

# vm_poller_interval is the number of seconds between VM polling cycles.
#   Increasing this value will lower the load on the system, and decreasing
#   it will improve responsiveness. The default value is good for testing, 
#   but could result excessive load on a busy system.
#
#   The default value is 5
#vm_poller_interval: 5

# job_poller_interval is the number of seconds between polling the Condor
#   Scheduler daemon. Increasing this value will lower the load on the
#   system, and decreasing it will improve responsiveness. The default 
#   value is good for testing, but could result excessive load on a
#   busy system. This is especially true if your Condor scheduler is busy.
#
#   The default value is 5
#job_poller_interval: 5

# machine_poller_interval is the number of seconds between polling the Condor
#   Collector daemon. Increasing this value will lower the load on the
#   system, and decreasing it will improve responsiveness. The default 
#   value is good for testing, but could result excessive load on a
#   busy system. This is especially true if your Condor scheduler is busy.
#
#   The default value is 5
#machine_poller_interval: 5

# cleanup_interval is the number of seconds between Cleanup cycles.
#   Increasing this value will lower the load on the system, and decreasing
#   it will improve responsiveness. The default value is good for testing, 
#   but could result excessive load on a busy system.
#
#   The default value is 5
#cleanup_interval: 5

# max_starting_vm is the limit on the number of VMs CS will allow to be in the
#   starting state at one time.
#
#   The default value is -1 (unlimited)
#max_starting_vm: -1

# max_destroy_threads is the limit on the number of threads CS will use to try
#   speed up shutting down multiple VMs, higher limit will speed up shutdowns of
#   large number of VMs, but may affect the load on the machine running CS.
#
#   The default value is 10
#max_destroy_threads: 10

# job_ban_timeout specifies how long to ban a job for when CS encounters an error
#   trying to boot a VM for that job. After the timeout period CS will consider
#   the job for starting VMs.
#
#   The default value is 60 (minutes)
#job_ban_timeout: 60

# ban_tracking specifies keeping track of VM creation errors and will ban
#   images from being booted on clusters if too many failures occur. The 
#   banned images are written out to the 'ban_file' in JSON format. The ban_file
#   can be edited or deleted and then CloudScheduler can be notified by using 
#   the SIGUSR2 signal (kill -s SIGUSR2 <pid>) to reload the ban information.
#
#   The default value is false
#ban_tracking: false

# ban_file is tha path to the file where banned vm / resources are stored
#   The information is stored in a JSON format that can edited manually or 
#   deleted, the file will only be created / written to when a new entry
#   is added. CloudScheduler will reload the file when given a SIGUSR2 signal.
#
#   The default value is /var/run/cloudscheduler.banned
#ban_file: /var/run/cloudscheduler.banned

# ban_min_track is the length of history for VM boot attempts that will be kept
#   and the minimum number of attempts before CloudScheduler will consider banning
#   an image from a resource.
#
#   The default value is 5
#ban_min_track: 5

# ban_failrate_threshold specifies the rate of failure on a resource before the
#   the image will be banned. It is a float value from (0.0 to 1.0] (not 0)
#   1.0 means the image must be always failing to boot.
#
#   The default value is 1.0
#ban_failrate_threshold: 1.0

# user_limit_file can be used to set a limit to the number of VMs a user may
#   have booted at one time. The file contains a JSON string with the users and
#   their limit.
#
#   Example JSON User Limit String:
#   { "user1": 5,
#     "user2": 10
#   }
#
#   The default value is None
#user_limit_file: None

# Use the pyopenssl library to extract x509 certificate expiry time.
# If False, then openssl forked subprocesses will be used.
#
# The default value is False
#use_pyopenssl: False

# job_proxy_refresher_interval specifies the amount of time, in seconds, between each job proxy
# credential expiry checks.  To disable job proxy refreshing altogether, simply set this
# value to -1
#
# The default value is -1 (not enabled)
#job_proxy_refresher_interval: -1

# job_proxy_renewal_threshold determines the amount of time, in seconds, 
# prior to proxy expiry date at which a job proxy will be refreshed
#
# The default value is 900 (15 minutes)
#job_proxy_renewal_threshold: 900

# vm_proxy_refresher_interval specifies the amount of time, in seconds, between each VM proxy
# credential expiry checks.  To disable VM proxy refreshing altogether, simply set this
# value to -1
#
# The default value is -1 (not enabled)
#vm_proxy_refresher_interval: -1

# vm_proxy_renewal_threshold determines the amount of time, in seconds, 
# prior to proxy expiry date at which a VM proxy will be refreshed
#
# The default value is 3600 (60 minutes)
#vm_proxy_renewal_threshold: 3600

# vm_proxy_shutdown_threshold determines the amount of time, in seconds, 
# prior to proxy expiry date at which a VM will be shutdown to avoid entering 
# an expired proxy state.
#
# The default value is 1800 (30 minutes)
#vm_proxy_shutdown_threshold: 1800

# vm_connection_fail_threshold determines the amount of time, in seconds,
# that cloudscheduler will allow a refused / failed connection to a cloud service
# until it considers VMs on that cloud is experiencing a problem and disable.
#
# The default value is 1800 (30 minutes)
#vm_connection_fail_threshold: 1800

# connection_fail_disable_time is the length of time Cloud Scheduler will disable
# a cloud for when it has been unable to connect to it for extended periods
#
# The default value is 7200 (2 hours)
#connection_fail_disable_time: 7200

# vm_idle_threshold determines how long a VM can remain idle while there are potential idle jobs
# waiting to run on it, this is typically caused by mis-configured job requirements.
# If cloud scheduler determines job is unable to run due to bad +VM* requirements it will shutdown
# the idle VM so new VMs using the idle jobs +VM* parameters can be booted. If cloudscheduler
# is unable to determine why the job is not running (possible due to requirements conflicts) the 
# job will attempt to be held.

# The default value is 300 (5 minutes)
#vm_idle_threshold: 300

# proxy_cache_dir determines where user cached user proxies
# will be stored.
#
# The default is to simply store them under the system's temp file
# directory.
# In a production setup, you might want to change that to a directory
# created especially for that.
#
#proxy_cache_dir: /tmp

# myproxy_logon_command is the path to your myproxy-logon command.
#
# In many cases, this will be in your path, and this value does not
# need to be configured. However, if you have a non-standard setup,
# you may configure the path here.
#
# The default is to look for "myproxy-logon" in your path.
#
#myproxy_logon_command: myproxy-logon

# override_vmtype if this is set to 'true', cloud scheduler will set
# the VMType value on the VM equal to the requested value from the job
# requesting it. You generally don't want this, except in scpecial cases,
# because it can make it difficult to debug problems with your setup.
#
# The default value is false
#
#override_vmtype: false

# vm_reqs_from_condor_reqs will allow cloud scheduler to attempt to extract
# some of the needed VM requirements from the Condor Requirements attribute.
# If VMMemory, VMCpuCores, or VMStorage, are not specified in the job 
# cloud_scheduler can try to fill in these attributes from Memory, Cpus, and
# Disk in the Requirements expression instead of using the default values.
#
# The default value is false
#vm_reqs_from_condor_reqs: false

# adjust_insufficient_resources will let Cloud scheduler automatically adjust it's
# available resources on a cloud if the cloud reports having insufficient available.
# In order to have the resources reset to their original values the cloud_resources
# must be reloading via a reconfig, quickrestart, or restart.
#
# The default value is false
#adjust_insufficient_resources: false

[job]

# The following configuration options are to set the default Job VM parameters
# These options are used to determine the VM specification

# default_VMType is the type of the VM - this type must match what is set
#   in VMLoc or VMAMI image.
#   the default value is 'default'
#default_VMType= default

#default_VMNetwork is the type of Nimbus network the VM will try to boot on
#   common values are 'private' or 'public' blank means it will try to use any network
#   this value is ignored for EC2 based VMs
#
#   the default value is an empty string
#default_VMNetwork=


# default_VMCPUArch is the CPU Architecture the VM needs to use
#   this can either be 'x86' or 'x86_64' for 32-bit or 64-bit VMs
#
#   the default value is "x86"
#default_VMCPUArch= x86

# default_VMHypervisor is the type of hypervisor the VM image needs to run on
#   either 'kvm', 'xen', or 'kvm,xen' if using a dual-hypervisor image
#
#   the default value is "xen"
#default_VMHypervisor=xen

# default_VMName is a name given to the VM for identifcation it can be any string
#
#   the default value is "Default-Image"
#default_VMName= Default-Image

# default_VMLoc specifys a URL to use for booting a VM on a Nimbus cloud
#
#   the default value is an empty string
#default_VMLoc= 

# default_VMAMI specifies an AMI to boot an image on an EC2 service cloud (such as Amazon EC2)
#
#   the default value is an empty string
#default_VMAMI= 

# default_VMMem specifies the amount of memory for a VM to use.
#
#   the default is 512
#default_VMMem= 512

# default_VMCPUCores specifies the number of VCPUs for a VM.
#
#   the default is 1
#default_VMCPUCores= 1

# default_VMStorage specifies the amount of scratch space(in GBs) attached to a VM.
#
#   the default is 1
#default_VMStorage= 1

# default_VMInstanceType specifies the EC2 instance type.
#
#   the default is an empty string (which will default to m1.small)
#default_VMInstanceType=

# default_VMInstanceTypeList specifies the EC2 instance type for each cloud.
# string must be in the form of "host_address:instance_type,host_address2:instance_type"
#
#   the default is an empty string
#default_VMInstanceTypeList=

# default_VMMaximumPrice specifies the Maximum Price for Amazon spot pricing to use.
#
#   the default is 0 (no maximum)
#default_VMMaximumPrice= 0

# default_VMProxyNonBoot specifies if the x509userproxy in the job should only
#   be used for the job and image retreival and not to boot VMs.
#
#   the default is False (use the x509userproxy to boot VMs as well)
#default_VMProxyNonBoot: False

# default_VMUserData specifies the EC2 user data which will be passed on to 
#   metadata service and eventually into the virtual machine.
#
#   there is no default
#default_VMUserData: /your/user_data

[logging]

# log_level specifies how much information from Cloud Scheduler to log. 
#           
#   Choose from VERBOSE, DEBUG, INFO, WARNING, ERROR and CRITICAL
#   The default is INFO
#
#   WARNING!!! - DO NOT USE VERBOSE WITH LARGE NUMBERS OF JOBS OR DEBUG 
#                WITH VERY LARGE NUMBERS OF JOBS
#log_level: INFO

# log_format is the format of the logging output. It is a string in the
#           Python logging module format, as specified in its module
#           documentation here:
#           http://docs.python.org/library/logging.html#formatter
#
#
#
#   The default is "%(asctime)s - %(levelname)s - %(threadName)s - %(message)s", 
#   which yields messages like the following:
#   "2010-07-13 11:02:08,722 - DEBUG - MainThread - message"
#log_format: %(asctime)s - %(levelname)s - %(threadName)s - %(message)s

# log_location specifies where to put the Cloud Scheduler log file. If left
#           blank, logging will just be sent to standard out
#
#log_location: /var/log/cloudscheduler.log

# log_stdout specifies whether to log to standard out. If set to true, this
#           will log to stdout in addition to logging to a file specified
#           in log_location, if set to false, Cloud Scheduler won't log to
#           stdout, even if there is no value specified for log_location
#
#   The default is false
#log_stdout: false

# log_max_size is the maximum filesize in Bytes for your log file.
#
#   The default is unlimited file size. This allows you to use logrotate
#   if you prefer to use it to manage the rotation of your log files.
#log_max_size: 2097152
