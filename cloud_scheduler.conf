#
# A sample configuration file for the cloud scheduler.
#

[global]

# cloud_resource_config is the path to the default list of resources you want
#           to use with Cloud Scheduler. If no file is supplied on the command
#           line (-c some_cloud | --cloud-config=some_cloud), this file will
#           be used.
#
cloud_resource_config: /etc/cloudscheduler/cloud_resources.conf 

# condor_retrieval_method is the method by which Cloud Scheduler gets job and 
#           resource data. Cloud Scheduler uses this data to determine how 
#           many VMs to boot for a user's jobs. There are two options: local
#           and soap. The SOAP method uses the Condor SOAP API to retrieve 
#           the data from Condor, and uses the condor_webservice_url and 
#           condor_collector_url options for contacting Condor. The local 
#           method simply runs the equivalent of 'condor_q -l' or
#           'condor_status -l' at the command line. If you like, you can 
#           change the command that Cloud Scheduler runs, for example, if
#           your central manager is on a different machine, you can make the
#           command something like 'ssh condor.your.org condor_status -l'.
#           This depends on the condor_q_command and the condor_status_command
#           options.
#
#           At this time, the soap method is considerably slower than the local
#           method.
#
#           The default is soap
#
#condor_retrieval_method: soap

# condor_webservice_url must point to the URL of the SOAP service on your
#           Condor pool, and the port on which it is running (usually 8080).
#                       
#   The default value is http://localhost:8080
condor_webservice_url: http://localhost:8080

# condor_collector_url must point to the URL of the SOAP service for your
#           Condor collector, and the port on which it is running (usually 9618).
#                       
#   The default value is http://localhost:9618
condor_collector_url: http://localhost:9618

# condor_q_command this is the command that Cloud Scheduler runs to get Condor
#           job data. If you like, you can change the command that Cloud 
#           Scheduler runs, for example, if your central manager is on a
#           different machine, you can make the command something like 
#           'ssh condor.your.org condor_q -l'.
#
#    The default value is 'condor_q -l'
#condor_q_command: condor_q -l

# condor_status_command this is the command that Cloud Scheduler runs to get Condor
#           machine data. If you like, you can change the command that Cloud 
#           Scheduler runs, for example, if your central manager is on a
#           different machine, you can make the command something like 
#           'ssh condor.your.org condor_status -l'.
#
#    The default value is 'condor_status -l'
#condor_status_command: condor_status -l

# condor_off_command this is the command that Cloud Scheduler runs to manange VMs
#           in the condor pool. If the central manager is on a different machine
#           you'll need to set a cloudscheduler_ssh_key below.
#
#    The default value is '/usr/sbin/condor_off
#condor_off_command: /usr/sbin/condor_off

# condor_on_command this is the command that Cloud Scheduler runs to manange VMs
#           in the condor pool. If the central manager is on a different machine
#           you'll need to set a cloudscheduler_ssh_key below.
#
#    The default value is '/usr/sbin/condor_on
#condor_on_command: /usr/sbin/condor_on

# ssh_path - location of ssh
#
#   The default is /usr/bin/ssh
#ssh_path: /usr/bin/ssh

# condor_host_on_vm is the hostname of the central manager that the Condor
#           daemons on the VM connect to. This is normally derived from the
#           condor_webservice_url option, but some setups (for example, those
#           that use OpenVPN) might need a diferent hostname for the VMs than
#           for Cloud Scheduler.
#
#   The default value is the hostname from condor_webservice_url. If this value
#   is localhost, it won't be sent to the VM.
#
#condor_host_on_vm: your.condor.server.edu

# condor_context_file is the location on your VM image where cloud_scheduler
#           should write the address of your Condor central manager machine
#           This is required to automatically contextualize your VM to point
#           to your Condor Pool
#                       
#   The default value is nothing, so no contextualization will happen unless
#   a value is specifically placed here
#condor_context_file: /etc/condor/central_manager

# vm_lifetime is the maximum time in minutes that you would like your VMs to
#           live.  Cloud Scheduler may shut them down before this point, but
#           this is the length of time that will be leased from cloud resources.
#
#   The default is 10080 minutes (1 week)
#vm_lifetime: 10080

# cert_file is the location of the (x509 or other) certificate that you would
#           like copied to your virtual machine. This is useful for setting
#           up VPN connections
#
#   There is no default.
#cert_file: /your/cert.pem

# key_file is the location of the (x509 or other) key that you would
#           like copied to your virtual machine. This is useful for setting
#           up VPN connections
#
#   There is no default.
#key_file: /your/key.pem

# cert_file_on_vm is where the (x509 or other) certificate cert_file
#           will be copied to on the booted VM.
#
#   The default is the location of cert_file
#cert_file_on_vm: /your/cert.pem

# key_file_on_vm is where the (x509 or other) key key_file
#           will be copied to on the booted VM.
#
#   The default is the location of key_file
#key_file_on_vm: /your/cert.pem

# cloudscheduler_ssh_key is the ssh key CloudScheduler will use to execute 
#           commands on the Condor central manager. This needs to be
#           a password-less key accessible by CloudScheduler.
#
#   There is no default.
#cloudscheduler_ssh_key: /your/.ssh/ssh_key

# image_attach_device is the device the image specified for a job is attached
#           to. 
#                       
#   The default value is sda
#image_attach_device: sda

# scratch_attach_device is the device the scratch space specified for a job is
#           attached to. 
#                       
#   The default value is sdb
#scratch_attach_device: sdb

# info_server_port is the port that the xmlrpc server that serves information
#           to tools like cloud_status uses. You may need to change this
#           to something other than the default if you have a conflict
#           with some other program, but you probably won't need to.
#
#   The default value is 8111
#info_server_port: 8111

# workspace_path is the path to the workspace (or workspace.sh) executable
#           used by Cloud Scheduler to start VMs on Nimbus resources.
#
#   The default value is "workspace", which assumes the executable is
#   in the path.
#workspace_path: /path/to/workspace
#
# persistence_file is the path to the Cloud Scheduler persistence file
#           which maintains Cloud Scheduler state information in case
#           of an unexpected exit from Cloud Scheduler (power outage, etc)
#
#   The default value is /var/run/cloudscheduler.persistence
#persistence_file: /var/run/cloudscheduler.persistence

# polling_error_threshold is the number of times a VM returns a error
#           during status polling before being shutdown
#   The default value is 10
# polling_error_threshold: 10

# condor_register_time_limit is the number of minutes Cloud Scheduler waits
# for a VM to register with Condor before determining there has been an error
# during boot and will shutdown the VM.
#   The default value is 15 (minutes)
#condor_register_time_limit: 15

# scheduling_algorithm specifies how Cloud Scheduler will schedule jobs.
#           'fairshare' Attempts to give each user an equal amount of
#           cloud resources to use, and balance resources between users.
#           It includes several options regarding how machines are shutdown,
#           sharing metrics, and support for high priority jobs
#
#   The default value is 'fairshare'
#scheduling_algoritm: fairshare

# job_distribution_type specifies how Cloud Scheduler will determine job shares.
#           for 'normal' distribution, a users' jobs will be evalutated based on 
#           priority and jobs of same priority are treated first in, first out.
#           for 'split' distribution, a users' jobs will be evaluated based on
#           priority and jobs of the same priority will get a split of their share
#
#   The default valus is 'normal'
#job_distribution_type: normal

# graceful_shutdown specifies if you want machines to only shutdown when no
#           job is running on them, this requires using condor_hold and 
#           condor_release on jobs and can affect performance, but will
#           prevent a job from being rescheduled due to Cloud_Scheduler
#           shutting down a job's VM once it has started running
#
#   The default is false
#graceful_shutdown: false

# gradeful_shutdown_method specifies the way CloudScheduler will shutdown
#           machines to minimize job interuptions.
#           'hold' will use condor_hold & condor_release to handle this
#           'off' will use condor_off to peacefully stop the condor startd
#           on the VM. This requires a password-less ssh to be setup from 
#           CloudScheduler to the Condor centeral manager. It is preferable
#           to use 'off' if possible.
#   The default is 'hold'
#graceful_shutdown_method: hold

# scheduling_metric selects the type of scheduling cloud_scheduler will
# use to balance resources between users.
#    The default value is slot, other option(s) are: memory, memory_cpu, memory_cpu_storage
#scheduling_metric: slot

# The distribution weights are used for the memory_cpu, and memory_cpu_storage 
#   scheduling metrics to adjust how Cloud Scheduler will balance resources.
#   Use a floating point value greater than 0.
#   The default is 1.0 for all weights.
#cpu_distribution_weight = 1.0
#memory_distribution_weight = 1.0
#storage_distribution_weight = 1.0

# getclouds specifies if you want to use cloud monitoring data from the
#   cloud-aggregator. More information about cloud-aggregator is here
#   https://wiki.gridx1.ca/twiki/bin/view/Main/CloudAggregatorOverview
#
#   The default value is false
#getclouds: False

# high_priority_job_support enables or disables use of high priority jobs
#   if support for high priority jobs is disabled any jobs marked as high
#   priority will be treated as normal jobs.
#
#   The default value is false
# high_priority_job_support: False

# high_priority_job_weight is the weighting used to determine any increased
#   share of resources that Cloud Scheduler will try to allocate to high priority
#   jobs. Use positive integer values.
#
#   The default value is 1 (no weight)
#high_priority_job_weight: 1

# scheduler_interval is the number of seconds between VM scheduling cycles.
#   Increasing this value will lower the load on the system, and decreasing
#   it will improve responsiveness. The default value is good for testing, 
#   but could result excessive load on a busy system.
#
#   The default value is 5
#scheduler_interval: 5

# vm_poller_interval is the number of seconds between VM polling cycles.
#   Increasing this value will lower the load on the system, and decreasing
#   it will improve responsiveness. The default value is good for testing, 
#   but could result excessive load on a busy system.
#
#   The default value is 5
#vm_poller_interval: 5

# job_poller_interval is the number of seconds between polling the Condor
#   Scheduler daemon. Increasing this value will lower the load on the
#   system, and decreasing it will improve responsiveness. The default 
#   value is good for testing, but could result excessive load on a
#   busy system. This is especially true if your Condor scheduler is busy.
#
#   The default value is 5
#job_poller_interval: 5

# machine_poller_interval is the number of seconds between polling the Condor
#   Collector daemon. Increasing this value will lower the load on the
#   system, and decreasing it will improve responsiveness. The default 
#   value is good for testing, but could result excessive load on a
#   busy system. This is especially true if your Condor scheduler is busy.
#
#   The default value is 5
#machine_poller_interval: 5

# cleanup_interval is the number of seconds between Cleanup cycles.
#   Increasing this value will lower the load on the system, and decreasing
#   it will improve responsiveness. The default value is good for testing, 
#   but could result excessive load on a busy system.
#
#   The default value is 5
#cleanup_interval: 5

# ban_tracking specifies keeping track of VM creation errors and will ban
#   images from being booted on clusters if too many failures occur. The 
#   banned images are written out to the 'ban_file' in JSON format. The ban_file
#   can be edited or deleted and then CloudScheduler can be notified by using 
#   the SIGUSR2 signal (kill -s SIGUSR2 <pid>) to reload the ban information.
#
#   The default value is false
#ban_tracking: false

# ban_file is tha path to the file where banned vm / resources are stored
#   The information is stored in a JSON format that can edited manually or 
#   deleted, the file will only be created / written to when a new entry
#   is added. CloudScheduler will reload the file when given a SIGUSR2 signal.
#
#   The default value is /var/run/cloudscheduler.banned
#ban_file: /var/run/cloudscheduler.banned

# ban_min_track is the length of history for VM boot attempts that will be kept
#   and the minimum number of attempts before CloudScheduler will consider banning
#   an image from a resource.
#
#   The default value is 5
#ban_min_track: 5

# ban_failrate_threshold specifies the rate of failure on a resource before the
#   the image will be banned. It is a float value from (0.0 to 1.0] (not 0)
#   1.0 means the image must be always failing to boot.
#
#   The default value is 1.0
#ban_failrate_threshold: 1.0

# job_proxy_refresher_interval specifies the amount of time, in seconds, between each job proxy
# credential expiry checks.  To disable proxy refreshing altogether, simply set this
# value to -1
#
# The default value is -1 (not enabled)
#job_proxy_refresher_interval: -1

# job_proxy_renewal_threshold determines the amount of time, in seconds, 
# prior to proxy expiry date at which a proxy will be refreshed
#
# The default value is 900 (15 minutes)
#job_proxy_renewal_threshold: 900

[job]

# The following configuration options are to set the default Job VM parameters
# These options are used to determine the VM specification

# default_VMType is the type of the VM - this type must match what is set
#   in VMLoc or VMAMI image.
#   the default value is 'default'
#default_VMType= "default"

#default_VMNetwork is the type of Nimbus network the VM will try to boot on
#   common values are 'private' or 'public' blank means it will try to use any network
#   this value is ignored for EC2 based VMs
#
#   the default value is ""
#default_VMNetwork=""


# default_VMCPUArch is the CPU Architecture the VM needs to use
#   this can either be 'x86' or 'x86_64' for 32-bit or 64-bit VMs
#
#   the default value is "x86"
#default_VMCPUArch= "x86"

# default_VMName is a name given to the VM for identifcation it can be any string
#
#   the default value is "Default-Image"
#default_VMName= "Default-Image"

# default_VMLoc specifys a URL to use for booting a VM on a Nimbus cloud
#
#   the default value is ""
#default_VMLoc= ""

# default_VMAMI specifies an AMI to boot an image on an EC2 service cloud (such as Amazon EC2)
#
#   the default value is ""
#default_VMAMI= ""

# default_VMMem specifies the amount of memory for a VM to use.
#
#   the default is 512
#default_VMMem= 512

# default_VMCPUCores specifies the number of VCPUs for a VM.
#
#   the default is 1
#default_VMCPUCores= 1

# default_VMStorage specifies the amount of scratch space(in GBs) attached to a VM.
#
#   the default is 1
#default_VMStorage= 1

# default_VMInstanceType specifies the EC2 instance type.
#
#   the default is ""
#default_VMInstanceType= ""

# default_VMMaximumPrice specifies the Maximum Price for Amazon spot pricing to use.
#
#   the default is 0 (no maximum)
#default_VMMaximumPrice= 0

[logging]

# log_level specifies how much information from Cloud Scheduler to log. 
#           
#   Choose from VERBOSE, DEBUG, INFO, WARNING, ERROR and CRITICAL
#   The default is INFO
#log_level: INFO

# log_format is the format of the logging output. It is a string in the
#           Python logging module format, as specified in its module
#           documentation here:
#           http://docs.python.org/library/logging.html#formatter
#
#
#
#   The default is "%(asctime)s - %(levelname)s - %(threadName)s - %(message)s", 
#   which yields messages like the following:
#   "2010-07-13 11:02:08,722 - DEBUG - MainThread - message"
#log_format: %(asctime)s - %(levelname)s - %(threadName)s - %(message)s

# log_location specifies where to put the Cloud Scheduler log file. If left
#           blank, logging will just be sent to standard out
#
#log_location: /var/log/cloudscheduler.log

# log_stdout specifies whether to log to standard out. If set to true, this
#           will log to stdout in addition to logging to a file specified
#           in log_location, if set to false, Cloud Scheduler won't log to
#           stdout, even if there is no value specified for log_location
#
#   The default is false
#log_stdout: false

# log_max_size is the maximum filesize in Bytes for your log file.
#
#   The default is unlimited file size. This allows you to use logrotate
#   if you prefer to use it to manage the rotation of your log files.
#log_max_size: 2097152
